method: conv_onet
data:
  input_type: pointcloud
  classes: [04379243, 02958343, 02691156]
  path: data/ShapeNet
  pointcloud_n: 3000
  pointcloud_noise: 0.005
  points_subsample: 2048
  points_file: points.npz
  points_iou_file: points.npz
  voxels_file: null
model:
  decoder: simple_local
  encoder: pointnet_local_pool
  encoder_kwargs:
    hidden_dim: 32
    plane_type: ['xz', 'xy', 'yz']
    plane_resolution: 64
    unet: True
    unet_kwargs:
      depth: 4
      merge_mode: concat
      start_filts: 32
  decoder_kwargs:
    sample_mode: bilinear # bilinear / nearest
    hidden_size: 32
  c_dim: 32
  embedding_mode: 'cat'  # or 'encoder' or 'none'
  embedding_dim: 32  # size of embedding vector
  num_classes: 3    # number of classes in the dataset
training:
  out_dir:  out/pointcloud/shapenet_3plane_simple_cat_3class
  batch_size: 64
  print_every: 100
  visualize_every: 1000
  checkpoint_every: 1000
  validate_every: 2000
  backup_every: 2000
  model_selection_metric: iou
  model_selection_mode: maximize
  n_workers: 8
  n_workers_val: 4
test:
  threshold: 0.2
  eval_mesh: true
  eval_pointcloud: false
  model_file: model_best.pt
generation:
  vis_n_outputs: 2
  refine: false
  n_x: 128
  n_z: 1
=======
  dataset: Shapes3D
  path: data/shapenetcorev2_hdf5_2048
  watertight_path: data/watertight
  classes: null
  input_type: img
  train_split: train
  val_split: val
  test_split: test
  dim: 3
  points_file: points.npz
  points_iou_file: points.npz
  multi_files: null
  points_subsample: 1024
  points_unpackbits: true
  model_file: model.off
  watertight_file: model_watertight.off
  img_folder: img
  img_size: 224 
  img_with_camera: false
  img_augment: false
  n_views: 24
  pointcloud_file: pointcloud.npz
  pointcloud_chamfer_file: pointcloud.npz
  pointcloud_n: 256
  pointcloud_target_n: 1024
  pointcloud_noise: 0.05
  voxels_file: 'model.binvox'
  padding: 0.1
model:
  decoder: simple
  encoder: pointnet_local_pool
  decoder_kwargs: {}
  encoder_kwargs: {}
  multi_gpu: false
  c_dim: 512
  embedding_mode: 'decoder'  # or 'encoder' or 'none'
  embedding_dim: 3  # size of embedding vector
  num_classes: 13    # number of classes in the dataset 
training:
  out_dir:  out/default
  batch_size: 64
  print_every: 200
  visualize_every: 1000
  checkpoint_every: 1000
  validate_every: 2000
  backup_every: 100000
  eval_sample: false
  model_selection_metric: loss
  model_selection_mode: minimize
  n_workers: 4
  n_workers_val: 4
test:
  threshold: 0.5
  eval_mesh: true
  eval_pointcloud: true
  remove_wall: false
  model_file: model_best.pt
generation:
  batch_size: 100000
  refinement_step: 0
  vis_n_outputs: 30
  generate_mesh: true
  generate_pointcloud: true
  generation_dir: generation
  use_sampling: false
  resolution_0: 32
  upsampling_steps: 2
  simplify_nfaces: null
  copy_groundtruth: false
  copy_input: true
  latent_number: 4
  latent_H: 8
  latent_W: 8
  latent_ny: 2
  latent_nx: 2
  latent_repeat: true
  sliding_window: False # added for crop generation